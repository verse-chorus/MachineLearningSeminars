{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVUW3yIlrHu5"
   },
   "source": [
    "# Векторное представления текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aN-JAK7XrHu7"
   },
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1l60J3BhJjHl"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet dvc[gdrive] fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BC3Te-tYrHu8"
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from mpl_toolkits import mplot3d\n",
    "from matplotlib import gridspec\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "\n",
    "import dvc.api\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "P0RVGWO-rHu8"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "6d3vU83SrHu8",
    "outputId": "ffe1668b-7fe9-44db-dcc9-2241b5ea2efb"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMLxenl58nYd"
   },
   "source": [
    "## Код для обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZItD3XrL85ur"
   },
   "outputs": [],
   "source": [
    "def train_on_batch(model, x_batch, y_batch, optimizer, loss_function):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(x_batch.to(model.device))\n",
    "    \n",
    "    loss = loss_function(output, y_batch.to(model.device))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MVNMl8DfmRhU"
   },
   "outputs": [],
   "source": [
    "def train_epoch(train_generator, model, loss_function, optimizer, callback = None):\n",
    "    epoch_loss = 0\n",
    "    total = 0\n",
    "    for it, (batch_of_x, batch_of_y) in enumerate(train_generator):\n",
    "        batch_loss = train_on_batch(model, batch_of_x, batch_of_y, optimizer, loss_function)\n",
    "        \n",
    "        if callback is not None:\n",
    "            with torch.no_grad():\n",
    "                callback(model, batch_loss)\n",
    "            \n",
    "        epoch_loss += batch_loss*len(batch_of_x)\n",
    "        total += len(batch_of_x)\n",
    "    \n",
    "    return epoch_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QCXwUfl51k3z"
   },
   "outputs": [],
   "source": [
    "def trainer(count_of_epoch, \n",
    "            batch_size, \n",
    "            dataset,\n",
    "            model, \n",
    "            loss_function,\n",
    "            optimizer,\n",
    "            lr = 0.001,\n",
    "            callback = None):\n",
    "\n",
    "    optima = optimizer(model.parameters(), lr=lr)\n",
    "    \n",
    "    iterations = tqdm(range(count_of_epoch), desc='epoch')\n",
    "    iterations.set_postfix({'train epoch loss': np.nan})\n",
    "    for it in iterations:\n",
    "        batch_generator = tqdm(\n",
    "            torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                        batch_size=batch_size, \n",
    "                                        shuffle=True, pin_memory=True), \n",
    "            leave=False, total=len(dataset)//batch_size+(len(dataset)%batch_size>0))\n",
    "        \n",
    "        epoch_loss = train_epoch(train_generator=batch_generator, \n",
    "                    model=model, \n",
    "                    loss_function=loss_function, \n",
    "                    optimizer=optima, \n",
    "                    callback=callback)\n",
    "        \n",
    "        iterations.set_postfix({'train epoch loss': epoch_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsGEvSBSrVwg"
   },
   "source": [
    "## Что это и зачем нужно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwCVJ5IDH17i"
   },
   "source": [
    "## Пример классификации твитов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnP0JTS8Qsya"
   },
   "source": [
    "### Загрузим выборку\n",
    "Рекомендую всем ознакомиться с dvc (если проблема аунтетификации, перезагрузите ядро юпитер)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkoqT588HtUZ"
   },
   "outputs": [],
   "source": [
    "with dvc.api.open(\n",
    "        'sem17/data/dataset.csv',\n",
    "        repo='https://github.com/andriygav/MachineLearningSeminars',\n",
    "        ) as f:\n",
    "        dataset = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6OXiLVZQ0zV"
   },
   "source": [
    "### Посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gISrWPvOYI_r"
   },
   "outputs": [],
   "source": [
    "dataset = dataset[dataset[['tag', 'message']].notnull().all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_VcSnHNFQmwY"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.sample(125000, random_state=42)\n",
    "train_mask = np.random.rand(len(dataset), ) < 0.8\n",
    "dataset_train = dataset[train_mask]\n",
    "dataset_test = dataset[~train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "zhf27RAPjqdu",
    "outputId": "e75d6ee8-389a-42e6-d3fc-e5e08bcd1143"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227654</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@JoelMadden YAYYY! proven I'm stronger in watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407532</th>\n",
       "      <td>1.0</td>\n",
       "      <td>@SamLuminate Isnt Ponderosa beautiful, ill be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>&amp;quot;the show&amp;quot; is playing and @leelonn i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548653</th>\n",
       "      <td>0.0</td>\n",
       "      <td>as u can see my pic aint working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526933</th>\n",
       "      <td>0.0</td>\n",
       "      <td>@wyndwalker dang sorry buddy i missed this som...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tag                                            message\n",
       "227654  1.0  @JoelMadden YAYYY! proven I'm stronger in watc...\n",
       "407532  1.0  @SamLuminate Isnt Ponderosa beautiful, ill be ...\n",
       "13992   0.0  &quot;the show&quot; is playing and @leelonn i...\n",
       "548653  0.0                   as u can see my pic aint working\n",
       "526933  0.0  @wyndwalker dang sorry buddy i missed this som..."
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "EGbakt6ujsud",
    "outputId": "3f9f358e-9f70-422e-9302-d1db3be57603"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tag\n",
       "count  100018.000000\n",
       "mean        0.499860\n",
       "std         0.500002\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BUGt80XQ-Zi"
   },
   "source": [
    "### Построим модель RNN (как 2 семинара назад)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Shbvw80CRnDW"
   },
   "outputs": [],
   "source": [
    "class RNNclassifier(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "    def __init__(self, vocab_dim, output_dim, emb_dim = 10, hidden_dim = 10, \n",
    "                 num_layers = 3, bidirectional = False, p=0.7):\n",
    "        super(RNNclassifier, self).__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_dim, emb_dim)\n",
    "        self.encoder = torch.nn.LSTM(emb_dim, hidden_dim, num_layers, \n",
    "                                     bidirectional=bidirectional, \n",
    "                                     batch_first=True, dropout=p)\n",
    "        self.linear = torch.nn.Linear(\n",
    "            2*num_layers*int(bidirectional + 1)*hidden_dim, \n",
    "            output_dim)\n",
    "    def forward(self, input):\n",
    "        input = self.embedding(input)\n",
    "        _, (h, c) = self.encoder(input)\n",
    "        act = torch.cat([h, c], dim=0).transpose(0, 1)\n",
    "        act = act.reshape(len(input), -1)\n",
    "        return self.linear(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "H4MQQD5nd36H"
   },
   "outputs": [],
   "source": [
    "class Tokenizer(object):\n",
    "    def __init__(self, word_to_ind, tokenizer):\n",
    "        self.word_to_ind = word_to_ind\n",
    "        self.tokenizer = tokenizer\n",
    "    def __call__(self, sentences, max_length = 10, pad_to_max_length = False):\n",
    "        tokens = self.tokenizer.tokenize_sents(sentences)\n",
    "        if not pad_to_max_length:\n",
    "            max_length = min(max_length, max(map(len, tokens)))\n",
    "        tokens = [['[CLS]']+s+['[SEP]'] + ['[PAD]']*(max_length-len(s)) \\\n",
    "                  if len(s) < max_length \\\n",
    "                  else ['[CLS]']+s[:max_length]+['[SEP]'] \\\n",
    "                  for s in tokens ]\n",
    "        ids = [[self.word_to_ind.get(w, self.word_to_ind['[UNK]']) for w in sent] for sent in tokens]\n",
    "        return torch.tensor(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7r6ogb_2XB0q"
   },
   "source": [
    "### Разбиение на слова --- токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUCtTjuDWDrY"
   },
   "outputs": [],
   "source": [
    "word_to_ind = {'[PAD]': 0, '[UNK]': 1, '[CLS]': 3, '[SEP]': 4}\n",
    "for sent in tqdm(dataset_train.values[:, 1]):\n",
    "    for word in RegexpTokenizer('[a-zA-Z]+|[^\\w\\s]|\\d+').tokenize(sent):\n",
    "        if word not in word_to_ind:\n",
    "            word_to_ind[word] = word_to_ind.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4GIei9IYgq9",
    "outputId": "82320c72-8f89-45ab-a9c8-c1a67bede40e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109561"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HI5u_PMWYuE9",
    "outputId": "734b1285-8c7c-4bc0-f4f9-f1c158316b40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(dataset_train.values[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nV3XAeJVgS9j"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(word_to_ind, RegexpTokenizer('[a-zA-Z]+|[^\\w\\s]|\\d+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "J5GmjlwmisRX"
   },
   "outputs": [],
   "source": [
    "train_data_sent = tokenizer(dataset_train.values[:, 1])\n",
    "test_data_sent = tokenizer(dataset_test.values[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KxGKpNVWiwSn"
   },
   "outputs": [],
   "source": [
    "dataset_train_pt = torch.utils.data.TensorDataset(\n",
    "    train_data_sent, torch.tensor(dataset_train.values[:, 0].tolist()).long())\n",
    "dataset_test_pt = torch.utils.data.TensorDataset(\n",
    "    test_data_sent, torch.tensor(dataset_test.values[:, 0].tolist()).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxWpZdZ-1fZU"
   },
   "source": [
    "### Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "BiigRiMkUWfY"
   },
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config['vocab_dim'] = len(word_to_ind)\n",
    "config['output_dim'] = len(set(dataset.values[:, 0]))\n",
    "config['emb_dim'] = 100\n",
    "config['hidden_dim'] = 10\n",
    "config['num_layers'] = 3\n",
    "config['bidirectional'] = False\n",
    "config['p'] = 0.7\n",
    "\n",
    "model = RNNclassifier(**config)\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cL6_9APz1ijh"
   },
   "source": [
    "### Качество до обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4RXQet33NIv",
    "outputId": "93ef2c10-44b0-4052-cdfd-7ec53c2e7233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.04      0.08     12474\n",
      "           1       0.50      0.96      0.66     12501\n",
      "\n",
      "    accuracy                           0.50     24975\n",
      "   macro avg       0.52      0.50      0.37     24975\n",
      "weighted avg       0.52      0.50      0.37     24975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_generator = torch.utils.data.DataLoader(dataset=dataset_test_pt, \n",
    "                                              batch_size=64, \n",
    "                                              pin_memory=True)\n",
    "            \n",
    "pred = []\n",
    "real = []\n",
    "model.eval()\n",
    "for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "    x_batch = x_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(x_batch)\n",
    "\n",
    "    pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "    real.extend(y_batch.cpu().numpy().tolist())\n",
    "\n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dceqH2my1woS"
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "wkY08WPv1zEF"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OepV4mCu2Dxj"
   },
   "outputs": [],
   "source": [
    "trainer(count_of_epoch=5, \n",
    "        batch_size=64, \n",
    "        dataset=dataset_train_pt,\n",
    "        model=model, \n",
    "        loss_function=loss_function,\n",
    "        optimizer = optimizer,\n",
    "        lr=0.001,\n",
    "        callback=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHHeP5ZD9AcP"
   },
   "source": [
    "### Качество после обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sJceEhE43Bf",
    "outputId": "f1924f87-2035-4e8c-a9ad-bb9f3a75b004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69     12474\n",
      "           1       0.69      0.61      0.65     12501\n",
      "\n",
      "    accuracy                           0.67     24975\n",
      "   macro avg       0.67      0.67      0.67     24975\n",
      "weighted avg       0.67      0.67      0.67     24975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_generator = torch.utils.data.DataLoader(dataset=dataset_test_pt, \n",
    "                                              batch_size=64, \n",
    "                                              pin_memory=True)\n",
    "            \n",
    "pred = []\n",
    "real = []\n",
    "test_loss = 0\n",
    "model.eval()\n",
    "for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "    x_batch = x_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(x_batch)\n",
    "\n",
    "    pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "    real.extend(y_batch.cpu().numpy().tolist())\n",
    "\n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QpNwKHcMx92"
   },
   "source": [
    "## Word2Vec (на основе vec формата fasttext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngzxcSiQ6Xb5"
   },
   "source": [
    "Используя опыт предыдущего семинара хочется \"дообучать\" нейросеть вместо того, чтобы обучать с нуля.\n",
    "\n",
    "Предлагается к примеру использовать предобученный слой nn.Embedings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r3Z8879YLwR"
   },
   "source": [
    "### Скачивание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DffXHIKINWcL"
   },
   "outputs": [],
   "source": [
    "!dvc get https://github.com/andriygav/MachineLearningSeminars sem17/data/cc.en.10.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e71iykPGVpAA"
   },
   "source": [
    "### Загрузка fasttext модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVqMkJuVM8Bz"
   },
   "outputs": [],
   "source": [
    "ft = fasttext.load_model('cc.en.10.bin', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mh2aqP_tWbVL"
   },
   "source": [
    "### Генерация VEC формата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yY81-I4t_5zH"
   },
   "outputs": [],
   "source": [
    "word_to_ind = dict()\n",
    "matrix_fasttext = []\n",
    "for i, w in enumerate(tqdm(ft.get_words(on_unicode_error='replace'))):\n",
    "    v = ft.get_word_vector(w)\n",
    "    if w not in word_to_ind:\n",
    "        word_to_ind[w] = i\n",
    "        matrix_fasttext.append(v)\n",
    "for w in ['[PAD]', '[UNK]', '[CLS]', '[SEP]']:\n",
    "    word_to_ind[w] = word_to_ind.__len__()\n",
    "    matrix_fasttext.append(np.zeros_like(matrix_fasttext[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RDgh3UHX2AJ"
   },
   "source": [
    "### Получения векторизаваных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "FQOF1Of3Az-q"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(word_to_ind, RegexpTokenizer('[a-zA-Z]+|[^\\w\\s]|\\d+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mhNmyRyyBL3Q"
   },
   "outputs": [],
   "source": [
    "train_data_sent = tokenizer(dataset_train.values[:, 1])\n",
    "test_data_sent = tokenizer(dataset_test.values[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OZ1EjVHJBSbK"
   },
   "outputs": [],
   "source": [
    "dataset_train_pt = torch.utils.data.TensorDataset(\n",
    "    train_data_sent, torch.tensor(dataset_train.values[:, 0].tolist()).long())\n",
    "dataset_test_pt = torch.utils.data.TensorDataset(\n",
    "    test_data_sent, torch.tensor(dataset_test.values[:, 0].tolist()).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4-Qn5N8X6J1"
   },
   "source": [
    "### Инициализация моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "prhhkqMJBUxB"
   },
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config['vocab_dim'] = len(word_to_ind)\n",
    "config['output_dim'] = len(set(dataset.values[:, 0]))\n",
    "config['emb_dim'] = 10\n",
    "config['hidden_dim'] = 10\n",
    "config['num_layers'] = 3\n",
    "config['bidirectional'] = False\n",
    "config['p'] = 0.7\n",
    "\n",
    "model = RNNclassifier(**config)\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IKVa-2rX9Yy"
   },
   "source": [
    "### Использование VEC формата фастекста в модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YJWF11MODdM",
    "outputId": "c8116d51-0606-4f1a-d9c1-a0c820804ff1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNclassifier(\n",
       "  (embedding): Embedding(2000004, 10)\n",
       "  (encoder): LSTM(10, 10, num_layers=3, batch_first=True, dropout=0.7)\n",
       "  (linear): Linear(in_features=60, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(torch.tensor(matrix_fasttext))\n",
    "for param in model.embedding.parameters():\n",
    "    param.requires_grad = False\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6W09s_jzYDOt"
   },
   "source": [
    "### Качество до обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2m5OZw0PCQW",
    "outputId": "392e9ac0-3a1a-4143-f302-e4c2652c546c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.98      0.66     12339\n",
      "           1       0.56      0.02      0.04     12643\n",
      "\n",
      "    accuracy                           0.50     24982\n",
      "   macro avg       0.53      0.50      0.35     24982\n",
      "weighted avg       0.53      0.50      0.34     24982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_generator = torch.utils.data.DataLoader(dataset=dataset_test_pt, \n",
    "                                              batch_size=64, \n",
    "                                              pin_memory=True)\n",
    "            \n",
    "pred = []\n",
    "real = []\n",
    "model.eval()\n",
    "for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "    x_batch = x_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(x_batch)\n",
    "\n",
    "    pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "    real.extend(y_batch.cpu().numpy().tolist())\n",
    "\n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jy75sy87YG5T"
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FOAEzf28PGPi"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQU2RL1iPKHJ"
   },
   "outputs": [],
   "source": [
    "trainer(count_of_epoch=5, \n",
    "        batch_size=64, \n",
    "        dataset=dataset_train_pt,\n",
    "        model=model, \n",
    "        loss_function=loss_function,\n",
    "        optimizer = optimizer,\n",
    "        lr=0.001,\n",
    "        callback=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "auihxGCSYInj"
   },
   "source": [
    "### Качество после обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAgfECGPPL69",
    "outputId": "76a80298-05dc-42bf-f780-420788b97fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62     12339\n",
      "           1       0.63      0.64      0.64     12643\n",
      "\n",
      "    accuracy                           0.63     24982\n",
      "   macro avg       0.63      0.63      0.63     24982\n",
      "weighted avg       0.63      0.63      0.63     24982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_generator = torch.utils.data.DataLoader(dataset=dataset_test_pt, \n",
    "                                              batch_size=64, \n",
    "                                              pin_memory=True)\n",
    "            \n",
    "pred = []\n",
    "real = []\n",
    "model.eval()\n",
    "for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "    x_batch = x_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(x_batch)\n",
    "\n",
    "    pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "    real.extend(y_batch.cpu().numpy().tolist())\n",
    "\n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iwy9w8hvM8kk"
   },
   "source": [
    "## Полноценный fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDh0lzmLYQ9h"
   },
   "source": [
    "### Задание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "MR_yn9r8S-Oa"
   },
   "outputs": [],
   "source": [
    "class RNNclassifierFastText(torch.nn.Module):\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "    def __init__(self, output_dim, emb_dim = 10, hidden_dim = 10, \n",
    "                 num_layers = 3, bidirectional = False, p=0.7):\n",
    "        super(RNNclassifierFastText, self).__init__()\n",
    "        self.encoder = torch.nn.LSTM(emb_dim, hidden_dim, num_layers, \n",
    "                                     bidirectional=bidirectional, \n",
    "                                     batch_first=True, dropout=p)\n",
    "        self.linear = torch.nn.Linear(\n",
    "            2*num_layers*int(bidirectional + 1)*hidden_dim, \n",
    "            output_dim)\n",
    "    def forward(self, input):\n",
    "        _, (h, c) = self.encoder(input)\n",
    "        act = torch.cat([h, c], dim=0).transpose(0, 1)\n",
    "        act = act.reshape(len(input), -1)\n",
    "        return self.linear(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "t_2EiCVbToOE"
   },
   "outputs": [],
   "source": [
    "class TokenizerFastText(object):\n",
    "    def __init__(self, ft, tokenizer):\n",
    "        self.ft = ft\n",
    "        self.tokenizer = tokenizer\n",
    "    def __call__(self, sentences, max_length = 10, pad_to_max_length = False):\n",
    "        tokens = self.tokenizer.tokenize_sents(sentences)\n",
    "        if not pad_to_max_length:\n",
    "            max_length = min(max_length, max(map(len, tokens)))\n",
    "        tokens = [['[CLS]']+s+['[SEP]'] + ['[PAD]']*(max_length-len(s)) \\\n",
    "                  if len(s) < max_length \\\n",
    "                  else ['[CLS]']+s[:max_length]+['[SEP]'] \\\n",
    "                  for s in tokens ]\n",
    "        vectors = [[self.ft.get_word_vector(w) for w in sent] for sent in tokens]\n",
    "        return torch.tensor(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elHpby4zYWQF"
   },
   "source": [
    "### Векторизация всех текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "CNe-ohgeT9_F"
   },
   "outputs": [],
   "source": [
    "tokenizer = TokenizerFastText(ft, RegexpTokenizer('[a-zA-Z]+|[^\\w\\s]|\\d+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "GTJUTniUUTYn"
   },
   "outputs": [],
   "source": [
    "train_data_sent = tokenizer(dataset_train.values[:, 1])\n",
    "test_data_sent = tokenizer(dataset_test.values[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Ceb4X9v4UXAx"
   },
   "outputs": [],
   "source": [
    "dataset_train_pt = torch.utils.data.TensorDataset(\n",
    "    train_data_sent, torch.tensor(dataset_train.values[:, 0].tolist()).long())\n",
    "dataset_test_pt = torch.utils.data.TensorDataset(\n",
    "    test_data_sent, torch.tensor(dataset_test.values[:, 0].tolist()).long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tQzNm6KYZXL"
   },
   "source": [
    "### Инициализация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "vzEDavh-Udz_"
   },
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config['output_dim'] = len(set(dataset.values[:, 0]))\n",
    "config['emb_dim'] = 10\n",
    "config['hidden_dim'] = 10\n",
    "config['num_layers'] = 3\n",
    "config['bidirectional'] = False\n",
    "config['p'] = 0.7\n",
    "\n",
    "model = RNNclassifierFastText(**config)\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIRIM8aMYbrB"
   },
   "source": [
    "### Качество до обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3cewLHEUqne",
    "outputId": "6acf20dd-71ee-4446-f9d0-9dd69f5c2589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12339\n",
      "           1       0.51      1.00      0.67     12643\n",
      "\n",
      "    accuracy                           0.51     24982\n",
      "   macro avg       0.25      0.50      0.34     24982\n",
      "weighted avg       0.26      0.51      0.34     24982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_generator = torch.utils.data.DataLoader(dataset=dataset_test_pt, \n",
    "                                              batch_size=64, \n",
    "                                              pin_memory=True)\n",
    "            \n",
    "pred = []\n",
    "real = []\n",
    "model.eval()\n",
    "for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "    x_batch = x_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(x_batch)\n",
    "\n",
    "    pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "    real.extend(y_batch.cpu().numpy().tolist())\n",
    "\n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gy0Pc5TZYdkI"
   },
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "GJpHIhMHUt-e"
   },
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsqlypyWUwq0"
   },
   "outputs": [],
   "source": [
    "trainer(count_of_epoch=5, \n",
    "        batch_size=64, \n",
    "        dataset=dataset_train_pt,\n",
    "        model=model, \n",
    "        loss_function=loss_function,\n",
    "        optimizer = optimizer,\n",
    "        lr=0.001,\n",
    "        callback=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eE6KLjyuYf8Y"
   },
   "source": [
    "### Качество после обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qb7lvyJfUzJ4",
    "outputId": "5d493a81-2449-47fe-f4af-04367ae69d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.78      0.67     12339\n",
      "           1       0.68      0.46      0.55     12643\n",
      "\n",
      "    accuracy                           0.62     24982\n",
      "   macro avg       0.63      0.62      0.61     24982\n",
      "weighted avg       0.63      0.62      0.61     24982\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_generator = torch.utils.data.DataLoader(dataset=dataset_test_pt, \n",
    "                                              batch_size=64, \n",
    "                                              pin_memory=True)\n",
    "            \n",
    "pred = []\n",
    "real = []\n",
    "model.eval()\n",
    "for it, (x_batch, y_batch) in enumerate(batch_generator):\n",
    "    x_batch = x_batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(x_batch)\n",
    "\n",
    "    pred.extend(torch.argmax(output, dim=-1).cpu().numpy().tolist())\n",
    "    real.extend(y_batch.cpu().numpy().tolist())\n",
    "\n",
    "print(classification_report(real, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkvEU2xBSz0Y"
   },
   "source": [
    "### Репрезентация слов (к сожалению плохой пример вышел из-за reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7fdtZ1DRe_S",
    "outputId": "0e0d9af6-f835-44d7-e977-2a73d2b36d50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.992003321647644, 'quickpet'),\n",
       " (0.9900119304656982, 'WOTA'),\n",
       " (0.9890460968017578, 'EBF4'),\n",
       " (0.9875317215919495, 'Photshop'),\n",
       " (0.9871889352798462, 'n810'),\n",
       " (0.9865942597389221, 'Snowtrooper'),\n",
       " (0.9860414266586304, 'Hamachi'),\n",
       " (0.9857523441314697, 'SKII'),\n",
       " (0.9834288954734802, 'PMD2'),\n",
       " (0.9827696084976196, 'CM10.2')]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_analogies(\"ios\", \"google\", \"android\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OEmiyBQaQtGQ",
    "outputId": "de8de6a9-bd88-48b2-db0c-42ae6b97a86e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9711152911186218, 'prince'),\n",
       " (0.9525136351585388, 'centurian'),\n",
       " (0.9459097981452942, 'knight'),\n",
       " (0.9448733329772949, 'musketeers'),\n",
       " (0.9438545107841492, 'bellringer'),\n",
       " (0.9397228360176086, 'victorius'),\n",
       " (0.9386382102966309, 'reverred'),\n",
       " (0.9370817542076111, 'rennaisance'),\n",
       " (0.9363556504249573, 'peasent'),\n",
       " (0.9356678128242493, 'halycon')]"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.get_nearest_neighbors('king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYzoIcpuNA-z"
   },
   "source": [
    "## Приемы unsupervise обучения эмбедингов. На основе BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVk_WeFfYrLJ"
   },
   "source": [
    "Основное приемущество векторного представления в том, что он обучается не зависимо от задачи.\n",
    "\n",
    "Для обучения представления используются вспомогательные задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание токена на основе окрестности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](images/img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание, что предложение следует за предыдущем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](images/img2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Другие задачи, которые можно дообучать на основе предобученых векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выбор варианта из списка альтернатив\n",
    "Примерный формат данных:\n",
    "* Premise: The man broke his toe. What was the CAUSE of this?\n",
    "* Alternative 1: He got a hole in his sock. \n",
    "* Alternative 2: He dropped a hammer on his foot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recognizing Textual Entailment\n",
    "Примерный формат данных:\n",
    "* Premise: If you help the needy, God will reward you.\n",
    "* Hypothesis: Giving money to a poor man has good consequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word in Context\n",
    "Примерный формат данных:\n",
    "* Context 1: There's a lot of trash on the **bed** of the river.\n",
    "* Context 2: I keep a glass of water next to my **bed** when I sleep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer To Passage\n",
    "Примерный формат данных\n",
    "* Question: Is france the same timezone as the uk.\n",
    "* Hypothesis: At the Liberation of France in the summer of 1944, Metropolitan France kept GMT+2 as it was the time then used by the Allies (British Double Summer Time). In the winter of 1944--1945, Metropolitan France switched to GMT+1, same as in the United Kingdom, and switched again to GMT+2 in April 1945 like its British ally. In September 1945, Metropolitan France returned to GMT+1 (pre-war summer time), which the British had already done in July 1945. Metropolitan France was officially scheduled to return to GMT+0 on November 18, 1945 (the British returned to GMT+0 in on October 7, 1945), but the French government canceled the decision on November 5, 1945, and GMT+1 has since then remained the official time of Metropolitan France."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Более подробно для русского и английского языка\n",
    "* [SuperGLUE](https://super.gluebenchmark.com)\n",
    "* [Russian SuperGLUE](https://russiansuperglue.com)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
